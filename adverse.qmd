---
title: "Exploring Preston and Gilthorpe's adversarial example"
author: "@Andi@tech.lgbt"
date: 2023-08-26
format:
  html:
    embed-resources: true
---

```{r}
#| warning: false
library(tidyverse)
library(magrittr)
library(car)
library(MatchIt)
library(WeightIt)
library(marginaleffects)
library(GGally)
library(cobalt)
library(mgcv)
library(quantreg)
library(bestNormalize)
```

Poking around the solution for *Using optimisation methods to generate adversarial datasets for propensity score methods with large post-adjustment bias*, available [yonder](https://osf.io/d279k/).

### Setup

First, get the data. The following code is hiked out of the Rmd provided by the authors.

```{r}
N <- 2 * 100

partition <- function(xs, k) {
  n <- length(xs)
  split(xs, rep(1:ceiling(n / k), each = k)[1:n])
}

unvectorise_data <- function(v, confounders) {
  data_length <- N * confounders
  intercept_length <- 1
  coeffs_length <- confounders
  residuals_length <- N

  data_v <- v[seq(1, data_length)]
  data_series <- partition(data_v, N)
  names(data_series) %<>% lapply(partial(paste0, "C")) |> unlist()
  data <- as_tibble(data_series)

  data %<>% mutate(X = c(rep(0, N / 2), rep(1, N / 2)))

  intercept <- v[data_length + 1]
  coeffs <- v[seq(data_length + intercept_length + 1,
                  data_length + intercept_length + coeffs_length)]
  residuals <- v[seq(
    data_length + intercept_length + coeffs_length + 1,
    data_length + intercept_length + coeffs_length + residuals_length
  )]
  list(
    data = data,
    intercept = intercept,
    coeffs = coeffs,
    residuals = residuals
  )
}

solution <- read.table("solution.csv",
                       header = TRUE,
                       row.names = 1) |>
  as.matrix() |>
  unvectorise_data(2)
```

Next, set the outcome variable:

```{r}
set_Y <- function(data, intercept, coeffs, residuals) {
  coeffs_dot <- data |>
    select(starts_with("C")) %>%
    `*`(matrix(
      coeffs,
      nrow = N,
      ncol = length(coeffs),
      byrow = TRUE
    )) |>
    transmute(dot = rowSums(across(.cols = everything()))) |>
    as.list() %>%
    `$`("dot")

  data |>
    mutate(Y = X + coeffs_dot + intercept + residuals)
}

dat <- with(solution,
            set_Y(data, intercept, coeffs, residuals))
```

### Explore

Take a peek:

```{r}
dat
```

```{r}
ggpairs(dat |> mutate(X = as.factor(X)), columns = c("C1", "C2", "X"),
        aes(alpha = .5))
```

Let's see how the covariates relate to the outcome, conditional on *X*:

```{r}
ggpairs(dat, columns = c("C1", "C2", "Y"),
        aes(colour = factor(X),
            alpha = .5))
```

The relationship between *C2* and *Y* depends on *X*: positive correlation for *X*=1 and negative for *X*=0. There's something odd going on with the relationship between *C1* and *C2*: the sign flips depending on *X*, also looks heteroskedastic.

Try to deal with interaction:

```{r}
mod <- lm(Y ~ X * (C1 + C2), data = mutate(dat, X = as.factor(X)))
```

```{r}
summary(mod)
```

So we probably can't ignore it...

```{r}
residualPlots(mod)
```

There's a quadratic (maybe) relationship between *C2* and residuals.

## Coarsened exact matching

Let's try CEM, ignoring this, and without covariate adjustment in the outcome model.

```{r}
match_cem <- matchit(X  ~ C1 + C2,
                     method = "cem",
                     data = dat,
                     estimand = "ATT")
match_cem_dat <- match.data(match_cem)
```

```{r}
match_cem
```

First look at the ASMD:

```{r}
love.plot(match_cem, 
          drop.distance = TRUE, 
          var.order = "unadjusted",
          abs = TRUE,
          thresholds = c(m = .1))
```

Matching improved balance.

Density plots:

```{r}
bal.plot(match_cem, "C1", which = "both")
```

```{r}
bal.plot(match_cem, "C2", which = "both")
```

Also looks improved.

Outcome model:

```{r}
outmod <- lm(Y ~ X, data = match_cem_dat, weights = weights)

avg_comparisons(outmod,
                variables = "X",
                vcov = ~subclass,
                newdata = subset(match_cem_dat, X == 1),
                wts = "weights")
```

We're told the true answer is 1 but this estimate is greater than that... what's going on...? Must be clues back in the original pairs plot.

## Linear regression

Wondering what the ATE looks like from the regression model where the covariates are at their means:

```{r}
lm(Y ~ X * (scale(C1) + scale(C2)), data = dat) |>
  confint()
```

Still over 1.

Try the obvious:

```{r}
lm(Y ~ X, data = dat) |>
  confint()
```

At least the CI includes 1.

Now the covariates:

```{r}
simp_ols <- lm(Y ~ X + C1 + C2, data = dat)
confint(simp_ols)
```

```{r}
ncvTest(simp_ols, ~C1)
ncvTest(simp_ols, ~C2)
ncvTest(simp_ols, ~C1 + C2)
ncvTest(simp_ols)
```

```{r}
set.seed(25082023)
Boot(simp_ols, R = 10000) |> confint()
```

Bootstrap CI includes the true answer 1 again... hmmmm!

## Quantile regression

How about fitting a quantile regression model instead, at the median:

```{r}
rq1 <- rq(Y ~ X + C1 + C2, data = dat, tau = 0.5)
summary(rq1)
```

That's also better. Is this a potential clue I wonder... Some genre of skew or heteroskedasticity that's dragging the estimate above 1...?

## Does fixing any skew help?

```{r}
set.seed(25082024)
C1_norm <- bestNormalize(dat$C1)
C2_norm <- bestNormalize(dat$C2)
```

```{r}
C1_norm
```

```{r}
C2_norm
```

```{r}
dat2 <- dat |>
  mutate(C1_t = C1_norm$x.t,
         C2_t = C2_norm$x.t)
```

```{r}
dat2
```

```{r}
match_cem2 <- matchit(X  ~ C1_t + C2_t,
                     method = "cem",
                     data = dat2,
                     estimand = "ATT")
match_cem_dat2 <- match.data(match_cem2)
```

```{r}
match_cem2
```

First look at the ASMD:

```{r}
love.plot(match_cem2, 
          drop.distance = TRUE, 
          var.order = "unadjusted",
          abs = TRUE,
          thresholds = c(m = .1))
```

Matching improved balance.

Density plots:

```{r}
bal.plot(match_cem2, "C1_t", which = "both")
```

```{r}
bal.plot(match_cem2, "C2_t", which = "both")
```

```{r}
outmod2 <- lm(Y ~ X * (C1_t + C2_t), data = match_cem_dat2,
              weights = weights)

avg_comparisons(outmod2,
                variables = "X",
                vcov = ~subclass,
                newdata = subset(match_cem_dat2, X == 1),
                wts = "weights")
```

```{r}
simp_ols2 <- lm(Y ~ X + C1_t + C2_t, data = dat2)
confint(simp_ols2)
```

Nope.


## How about influential data points?

We need a model. Could start with the simple OLS model, no interactions. We're primarily interested in anything that significantly shifts the estimate for X.

```{r}
dat$X_DFBETAS <- dfbetas(simp_ols)[,"X"]
```

We could use Bollen and Jackman's (1985) threshold:

```{r}
thresh <- 2/sqrt(nrow(dat))
thresh
```

Which points to:

```{r}
dat |>
  filter(abs(X_DFBETAS) > thresh)
```



```{r}
dat_noinf <- dat |>
  filter(abs(X_DFBETAS) <= thresh)
```

Let's try again with CEM:

```{r}
match_cem_noinf <- matchit(X  ~ C1 + C2,
                     method = "cem",
                     data = dat_noinf,
                     estimand = "ATT")
match_cem_dat_noinf <- match.data(match_cem_noinf)
```

```{r}
match_cem_noinf
```

First look at the ASMD:

```{r}
love.plot(match_cem_noinf, 
          drop.distance = TRUE, 
          var.order = "unadjusted",
          abs = TRUE,
          thresholds = c(m = .1))
```

Matching improved balance.

Density plots:

```{r}
bal.plot(match_cem_noinf, "C1", which = "both")
```

```{r}
bal.plot(match_cem_noinf, "C2", which = "both")
```

Also still looks improved.

Outcome model:

```{r}
outmod_noinf <- lm(Y ~ X, data = match_cem_dat_noinf, weights = weights)

avg_comparisons(outmod_noinf,
                variables = "X",
                vcov = ~subclass,
                newdata = subset(match_cem_dat_noinf, X == 1),
                wts = "weights")
```

OMG look at that estimate -- exactly 1! Excitement tempered somewhat by the fact that I've analysed this poor n=200 simulated dataset to within an inch of its existence. Really need to replicate the approach on (ideally) a large number of other similar datasets.

Also this feels naughty, since I've used OLS, pruned out observations that were influential, relative to the model I used, and then threw that at CEM. It's the reverse of what we usually want to do, i.e., use CEM as a non-parametric preprocessing step before applying a parametric model to estimate outcomes.

So now I'm wondering if DFBETAS is already defined for matching. It wouldn't be hard to do it but it'll be inefficient for large datasets:

1. Match.
2. Estimate outcomes model.
3. Leave each observation out in turn, reapply CEM, refit the outcomes model, and calculate DFBETAS, which is simply the shift in the coefficient for X divided by its SE.
4. Since the sample size for each run of step 3 is likely to vary, we need to choose a constant for the threshold indicating an influential observation. Maybe just the total sample going in.

Alternatively, and easier, we could just match once and calculate DFBETAS for the outcome model. Let's try...

First revisit the original match:

```{r}
match_cem
```

This was the outcomes model, without robust SE, but it'll do...:

```{r}
summary(outmod)
```

Add in the DFBETAS estimates:

```{r}
match_cem_dat$X_DFBETAS <- dfbetas(outmod)[,"X"]
```

```{r}
new_thresh <- 2/sqrt(nrow(match_cem_dat))
new_thresh
```

```{r}
match_cem_dat_noinf <- match_cem_dat |>
  filter(abs(X_DFBETAS) <= new_thresh) |>
  select(-c(weights, subclass))
match_cem_dat_noinf
```


Ten observations have been dropped off:

```{r}
nrow(match_cem_dat_noinf)
```

Now, go again (really should have wrapped this all in a function!):


```{r}
match_cem3 <- matchit(X  ~ C1 + C2,
                     method = "cem",
                     data = match_cem_dat_noinf,
                     estimand = "ATT")
match_cem_dat3 <- match.data(match_cem3)
```

```{r}
match_cem3
```

Look at the ASMD:

```{r}
love.plot(match_cem3, 
          drop.distance = TRUE, 
          var.order = "unadjusted",
          abs = TRUE,
          thresholds = c(m = .1))
```

Matching (still) improved balance.

Density plots:

```{r}
bal.plot(match_cem3, "C1", which = "both")
```

```{r}
bal.plot(match_cem3, "C2", which = "both")
```

Okay C2 looks a bit wilder?


```{r}
outmod3 <- lm(Y ~ X, data = match_cem_dat3, weights = weights)

avg_comparisons(outmod3,
                variables = "X",
                vcov = ~subclass,
                newdata = subset(match_cem_dat3, X == 1),
                wts = "weights")
```


Now the estimates is lower than 1 and the CI straddles 1.

Finally, try a doubly robust estimate:

```{r}
outmod3_dr <- lm(Y ~ X * (C1 + C2),
                 data = match_cem_dat3,
                 weights = weights)

avg_comparisons(outmod3_dr,
                variables = "X",
                vcov = ~subclass,
                newdata = subset(match_cem_dat3, X == 1),
                wts = "weights")
```

Even smaller estimate, but CI still includes 1.


## Overlap weights

I haven't touched propensity score methods yet.

If there's something funny going on with extreme values then we might expect overlap weights to be unbothered by them. However, they give us a different estimand: average treatment effect at overlap (ATO).

Let's see what happens; back to the original data:

```{r}
dat_weight <- weightit(X ~ C1 + C2,
              method = "glm",
              estimand = "ATO",
              data = dat)
dat_weight
```

```{r}
dat$OW <- dat_weight$weights
```

First, without any covariates in the outcome model:

```{r}
outmod_ato <- lm(Y ~ X, data = dat, weights = OW)

avg_comparisons(outmod_ato,
                variables = "X",
                vcov = "HC3",
                wts = "OW")
```

The CI just about includes 1.

If we make it doubly-robust, though, then it breaks:

```{r}
outmod_ato_dr <- lm(Y ~ X * (C1 + C2), data = dat, weights = OW)

avg_comparisons(outmod_ato_dr,
                variables = "X",
                vcov = "HC3",
                wts = "OW")
```

CI just excludes 1.




